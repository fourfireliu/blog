<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="内存," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="​       谈到Java并发，就要讲到Java内存模型，而Java内存模型又和内存屏障(Memory Barriers)有着千丝万缕的联系。Java内存模型遵守happens-before的规则，否则，Java多线程程序的执行顺序和执行结果完全无迹可寻。先来回顾一下happens-before规则：

程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作">
<meta property="og:type" content="article">
<meta property="og:title" content="关于内存屏障的阅读理解">
<meta property="og:url" content="http://ursa.cc/2016/06/13/about-memory-barriers/index.html">
<meta property="og:site_name" content="Ursa's Blog">
<meta property="og:description" content="​       谈到Java并发，就要讲到Java内存模型，而Java内存模型又和内存屏障(Memory Barriers)有着千丝万缕的联系。Java内存模型遵守happens-before的规则，否则，Java多线程程序的执行顺序和执行结果完全无迹可寻。先来回顾一下happens-before规则：

程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作">
<meta property="og:image" content="http://ursa.cc/2016/06/13/about-memory-barriers/cpu1.png">
<meta property="og:image" content="http://ursa.cc/2016/06/13/about-memory-barriers/cpu2.png">
<meta property="og:image" content="http://ursa.cc/2016/06/13/about-memory-barriers/cpu3.png">
<meta property="og:image" content="http://ursa.cc/2016/06/13/about-memory-barriers/cpu4.png">
<meta property="og:image" content="http://ursa.cc/2016/06/13/about-memory-barriers/cpu5.jpg">
<meta property="og:updated_time" content="2016-07-15T03:11:07.889Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="关于内存屏障的阅读理解">
<meta name="twitter:description" content="​       谈到Java并发，就要讲到Java内存模型，而Java内存模型又和内存屏障(Memory Barriers)有着千丝万缕的联系。Java内存模型遵守happens-before的规则，否则，Java多线程程序的执行顺序和执行结果完全无迹可寻。先来回顾一下happens-before规则：

程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作">
<meta name="twitter:image" content="http://ursa.cc/2016/06/13/about-memory-barriers/cpu1.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> 关于内存屏障的阅读理解 | Ursa's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Ursa's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">owner--fourfireliu</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                关于内存屏障的阅读理解
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-13T16:49:16+08:00" content="2016-06-13">
              2016-06-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/操作系统/" itemprop="url" rel="index">
                    <span itemprop="name">操作系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/06/13/about-memory-barriers/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/06/13/about-memory-barriers/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
 	    <span>&nbsp; | &nbsp;
	    <span id="busuanzi_value_page_pv" ></span>次阅读</span>    
	  

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>​       谈到Java并发，就要讲到Java内存模型，而Java内存模型又和内存屏障(Memory Barriers)有着千丝万缕的联系。Java内存模型遵守happens-before的规则，否则，Java多线程程序的执行顺序和执行结果完全无迹可寻。先来回顾一下happens-before规则：</p>
<ul>
<li>程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。</li>
<li>监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。</li>
<li>volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读。</li>
<li>传递性：如果A happens- before B，且B happens- before C，那么A happens- before C。</li>
</ul>
<p>happens-before规则的实现很大一部分是靠JVM编译器在生成的指令序列中插入内存屏障指令来实现的。内存屏障能保证该指令前后的代码操作不会被JVM编译器自作聪明地重排序，导致不可预知的后果。内存屏障的实现，则涉及到了操作系统里CPU cache memeory执行指令的原理和优化。最近有幸读到一篇牛人的论文<a href="http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf" target="_blank" rel="external">Memory Barriers: a Hardware View for Software Hackers</a>，通俗易懂，深有所得，试阐述一二。</p>
<p>指令的重排序极大的优化了cpu的性能，为了保证多核多线程指令的正常顺序，Memory Barries也应运而生。由于CPU的计算速度远远大于CPU从内存中读取写入数据的速度，为了提升性能，引入了Cache，现代CPU的架构最初如下：</p>
<img src="/2016/06/13/about-memory-barriers/cpu1.png" alt="cpu1" title="cpu1">
<p>当cpu加载数据时，首先尝试从cache中获取，这会导致一个cache miss，cpu将会等待很长时间(相对从cache中获取)从memory中获取该数据，之后每次都是从cache中取这个数据了(除非被其他缓存数据替换)。在多核系统中，当某个cpu要写(刷新)数据时(不管是写到它的cache或者写到memory)，由于是多核系统，要保证所有CPU缓存的一致性，首先要发送消息给其他cpu，通知它们这个数据已废弃(invalidated)，当收到其他所有cpu已废弃的回复后，它可以放心写数据了，如果这个缓存数据的状态(read-only)表示该数据缓存在其他cpu上也有至少一份，那么它就得先实现invalidated，然后再写数据，这称之为write-miss。</p>
<h3 id="Cache-Coherence-Protocols"><a href="#Cache-Coherence-Protocols" class="headerlink" title="Cache Coherence Protocols"></a>Cache Coherence Protocols</h3><p>正因为不同的cpu有自己的cache，因此cache一致性(cache-coherence)的需求也就随之而生了。为了支持cache一致性，cache定义了多个状态MESI(modified, exclusive, shared, invalid)。</p>
<p>modified: 表示只有当前cpu cache存有该数据的缓存，而且cache中的数据是最新的，还未刷到内存里。如果当前cache不再想要存放该数据缓存，需要将它刷回内存里。</p>
<p>exclusive: 和modified很相似，不同在于cache中的数据和内存中的数据是一致的，数据退出cache不需要刷到内存里。</p>
<p>shared: 内存中数据是最新的，除了当前cache还有别的cpu cache也有数据的缓存。</p>
<p>invalid: 当前cache缓存无效，意味着新data进cache时，可以优先替换状态为invalid的缓存，因为无需做其他任何操作，不需要刷内存或者通知其他cpu cache保存一致性，不会有任何影响，代价是最低的。</p>
<h3 id="MESI-Protocol-Messages"><a href="#MESI-Protocol-Messages" class="headerlink" title="MESI Protocol Messages"></a>MESI Protocol Messages</h3><p>在代码执行过程中，各个CPU cache不断的在MESI状态中转换，在转换过程中，多个cpu之间也有着各种通信来保持一致性。记住，每个cpu管理自己的一个cache，数据状态是cache的，消息是cpu发的</p>
<p>read: 包含了要读取的数据的物理地址(memory地址作为cache的key值)，这是一个读取请求。</p>
<p>read response: 包含要读的数据 可能来自于其他cache或者直接来自memory，这是一个读取请求的回复。</p>
<p>invalidate: 包含了要废弃的memory地址，所有其他cache必须执行废弃该地址的的数据的操作并给出回复。</p>
<p>invalidate acknowledge: 尝试废弃缓存数据后，响应invalidate消息。</p>
<p>read invalidate: read和invalidate的合体，应该就是要其它cache废弃缓存，同时从内存里读出最新数据作为回复。</p>
<p>writeback: 消息中包含memory地址和数据，这条命令就是让处于modified状态的cache把数据刷回内存。</p>
<p>cpu之间消息传送导致cache状态转换关系图如下:</p>
<img src="/2016/06/13/about-memory-barriers/cpu2.png" alt="cpu2" title="cpu2">
<ul>
<li>Transition a: modified-exclusive，主要是cpu发出一个writeback消息。</li>
<li>Transition b: exclusive-modified，cpu更新了exclusive状态的cache数据，这个转换cpu没有发出接收任何消息。</li>
<li>Transition c: modified-invalidate，cpu收到了针对它的一个modified状态的数据的read-invalidate消息，cpu将会使该数据失效。(看来这里read-invalidate是读cache上的数据 什么时候需要这样的场景呢？为啥需要invalidate它呢？)</li>
<li>Transition d: invalidate-modified, cpu在一个废弃cache上执行一个read-modify-write操作，它发出一个read-invalidate消息，读取了某个数据的最新缓存值到自己的缓存上，并要求其他cpu invalidate它们可能的缓存，当它收到所有的invalidate response后，该转换完成。(和transition c的刚好一对)</li>
<li>Transition e: shared-modified, cpu在此cache中执行了一个read-modify-write的操作，意思就是场景就是(a=1) 这么一个操作，但是初始状态是shared 表示其他cpu cache里还有老的缓存，所以要同时给其他所有cpu发一个invalidate消息，等到收到所有的invalidate response这个转换才算完成。</li>
<li>Transition f: modified-shared, cpu cache这个数据状态是modified 收到一个read消息 然后返回data作为read response(可能还同时把它刷到memory了)(问题来了 shared到底有没有保证多个cache和memory数据一致呢)</li>
<li>Transition g: exclusive-shared, 这个和transition f很相像 区别就是f的数据来自于cache 有可能会刷回memory，这里则是数据来自于cache或memory，肯定不需要刷回memory。</li>
<li>Transition h: shared-exclusive, 使用场景是(cpu意识到它马上就要对这个cache的数据进行更新操作，那么它给其他所有的cpu发了一个这个数据的invalidate命令，导致其他cpu将这个缓存都写回到memory里 invalidate掉缓存)，因此这个转换要等收到所有的invalidate acknowledge才完成。这样这个cache是唯一拥有这个数据的缓存了。</li>
<li>Transition i: exclusive-invalidate, 使用场景(其他某个cpu对一个不在它缓存上的数据要执行一个read-modify-write的原子操作，因此它群发了一个read-invalidate消息，当前cpu收到这个消息，返回了read-response和invalidate acknowledge，这样看来 对exclusive read-invalidate是读缓存的即可)</li>
<li>Transition j: invalidate-exclusive, 使用场景(该cpu将要执行的代码是给某个在其他cache中有缓存的数据赋新值，因此它群发了一个read-invalidate消息，当它收集齐全read-response和invalidate-acknowledge时，转换完成，这意味着马上它就要做一个exclusive-modified的转换…那就是一行代码花了几个状态切换才完成。)</li>
<li>Transition k: invalidate-shared, 使用场景(该cpu要加载一个在别的cache的data，所以发了个read，当收到read response时，转换完成)</li>
<li>Transition l: shared-invalidate, 遭遇了transition j。</li>
</ul>
<a id="more"></a>
<p>由上可以发现一点，在transition j中，如果cpu0要给某个在别的cache中有缓存的memory地址赋新值，它必须发出一个invalidate 然后一直等到收集齐invalidate acknowledge才能进行操作。但反过来想想cpu0为什么一定要等cpu1的响应结果呢？无论cpu1那边有还是没有data缓存，cpu0都是要做赋新值的操作的，cpu1的原缓存值是多少然后过了多久做invalidate并不会影响cpu0的赋值结果(我们这里当然是假定cpu间的通信是永远不会丢失的，处于一个理想状态)。</p>
<p>考虑到这点，一个叫做store buffer的东东就出现了，cpu架构图也变成这样：</p>
<img src="/2016/06/13/about-memory-barriers/cpu3.png" alt="cpu3" title="cpu3">
<p>每个cpu和cache间都加了一个store buffer，它上连cpu下连cache，当cpu想写一个变量(给某个memory不管在不在它的cache里 赋新值)时，它直接把这个写操作(memory地址为key:新值为value)发到store buffer里，然后接着做别的操作。当最终其他cpu都invalidate好了(invalidate acknowledge都到齐了)，操作会从store buffer清除，而值会存放到cache里(所以store buffer是进去一个store操作，出来执行一个cache store操作)。</p>
<p>来看点代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span>;</span><br><span class="line">b = a + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">assert</span>(b == <span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<p>看起来这简直是不可能错的。但如果用的是上图的那种架构的cpu，就未必了，一起来看看，假设cpu0的cache缓存了a，cpu1的cache缓存了b，初始值都是0：</p>
<ol>
<li>cpu0执行a=1</li>
<li>cpu0发现a不在缓存里，因此cpu0群发一个read-invalidate消息，这就是transition j的场景，从invalidate-exclusive。</li>
<li>cpu0将所有的store操作都丢到store buffer里，a=1这个操作也不例外。</li>
<li>cpu1收到read-invalidate消息，最终清了cache, 返回read response和invalidate-acknowledge消息</li>
<li>cpu0开始执行下一条 b=a+1。</li>
<li>cpu0因为异步的store buffer流程没走完，自己的cache里没有，所以只能从cpu1那取，取的还是memory中老的a=0，并存在自己cache这。</li>
<li>cpu0于是把自己cache里的b=a+1 得到b=1</li>
<li>cpu0的store buffer终于等到了cpu1的invalidate-acknowledge，这样就可以把a=1写到cache里了，注意，这时的cpu0 cache里 a=1。</li>
<li>cpu0执行assert(b==2) 返回false。</li>
</ol>
<p>为什么会这样呢？原因就在cpu0里出现了两份变量a的copy，一份在cache里为0，一份在store buffer里为1。为了解决这个问题，硬件工程师们改变cpu策略，让cpu加载数据时先尝试读store buffer，然后再cache，那么架构图变为:</p>
<img src="/2016/06/13/about-memory-barriers/cpu4.png" alt="cpu4" title="cpu4">
<p>这样，上面第7步，cpu0先从store buffer中取到a为1，因此b=2，然后得到正常结果。</p>
<p>这样就没问题了吗？不，让我们看下面的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">var <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">var <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (b == <span class="number">0</span>) &#123;</span><br><span class="line">  	<span class="keyword">continue</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>假设cpu0执行foo()而cpu1执行bar()，同时a存在于cpu1的cache里而b存在于cpu0的cache里，我们来看看操作执行流程：</p>
<ol>
<li>cpu0执行a=1，因为a不在cpu0的cache里，因此cpu0发出一个read invalidate然后把a=1的操作放到store buffer里。 </li>
<li>cpu1执行 while(b==0) continue; 这里它不是赋值b，只是尝试获取b，b不在它的cache里，因此它发了个read消息出去。</li>
<li>cpu0执行b=1 因此b在它的cache里，它直接把cache里的值改为1就好，注意到在这里cpu0不会把b=1的操作放到store buffer里，虽然它肯定也是先在本地store buffer-cache这样的顺序load一遍b。改好以后b在cache中肯定处于modified状态。</li>
<li>cpu0收到read消息，于是将1返回出去，同时改状态为shared(我们先假设modified-shared同时是刷了memory的)，cpu1也收到了read response，于是把b=1存到cache里，它也是shared的。</li>
<li>cpu1于是跳出while循环，执行下一步，但这时cpu0的read invalidate还没到，因此cpu1取了自己的老缓存a=0，因此返回false。</li>
<li>cpu0的read invalidate紧赶慢赶总算到了，废弃了cpu1的老cache a，但已经太晚了。cpu0收到invalidate acknowledge然后store buffer把a=1 存到cache里 modified。</li>
</ol>
<p>这里为什么会和想要的结果不一样呢？因为cpu0的对一个变量的修改没有及时通知到cpu1上，但硬件工程师也没辙，因为不可能知道一个cpu的哪些操作会影响到另一个cpu的哪些操作，cpu1只是自顾自的做它的事，不知道有别的cpu已经废弃了它的缓存。因此，内存屏障(memory barrier)出现了：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">var <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  smp_mb();</span><br><span class="line">  b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">var <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (b == <span class="number">0</span>) &#123;</span><br><span class="line">  	<span class="keyword">continue</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>smp_mb()的作用是: 导致在下一次store指令之前，cpu必须处理完现有的store buffer，它可以有两个实现，要么在下一次执行store指令，把store buffer的指令执行完；要么把下一次store命令也放到store buffer里，不管这个变量是不是已经在自己的cache里了。这样的话，指令执行流程就变成了这样：</p>
<ol>
<li>cpu0执行a=1，因为a不在cpu0的cache里，因此cpu0发出一个read invalidate然后把a=1的操作放到store buffer里。 </li>
<li>cpu1执行 while(b==0) continue; 这里它不是赋值b，只是尝试获取b，b不在它的cache里，因此它发了个read消息出去。</li>
<li>cpu0执行smp_mb()，标记出所有目前的store buffer指令(目前a=1)</li>
<li>cpu0执行b=1 因为有了smp_mb()标记出store buffer里有值，它只能把b=1也放进store buffer。</li>
<li>cpu0收到read消息，于是将初始值0返回出去，同时改状态为shared(我们先假设modified-shared同时是刷了memory的)，cpu1也收到了read response，于是把b=0存到cache里，它也是shared的。</li>
<li>cpu1收到关于a的read invalidate消息，返回a=0然后invalidate了自己cache的a。</li>
<li>cpu0收到了a=0，存入cache，它现在是modified状态了。它现在开始处理store buffer，在cache中有a，直接改成a=1，接下来是b了，但b现在是share状态，因此发了一个invalidate消息(如果自己没有 那就是发read invalidate消息了).</li>
<li>cpu1收到invalidate消息，清掉自己的b=0的cache，在下一次循环中，又要用到b，只能发一个read消息，cpu0先收到之前的invalidate acknowledge消息，把自己的b改成1并刷入memory，现在它的b是exclusive状态，接下来它又收到read消息，将b=1回复给cpu1，同时它的b状态变为shared.</li>
<li>cpu1收到b=1后，终于可以跳出while了，接着，发现自己cache没有a，发消息从cpu0获得了正确的a=1，也返回了正确结果。</li>
</ol>
<p>解决了这个问题，新问题又来了，如果smp_mb经常用的话，那么每次store都需要等sotre buffer里的所有已有store处理完才能执行，而每个store必然伴随着一次read invalidate/invalidate消息的完全执行，那就相当于还是要完全等待每个acknowledge的返回。</p>
<p>怎样才能让invalidate acknowledge快速返回而不是要等cpu们真正把invalidate执行完毕才返回呢？硬件工程师给每个cpu增加了一个invalidate queues，架构图变为：</p>
<img src="/2016/06/13/about-memory-barriers/cpu5.jpg" alt="cpu5" title="cpu5">
<p>cpu收到一个invalidate消息时，立马把它放到invalidate queue里然后返回一个invalidate acknowledge，而不等待执行invalidate.而cpu要发出invalidate消息时，必须确保invalidate queue里没有相关变量或者已经处理完成。但这个新增机制也可能影响memory barrier的正确性，我们接下来看，假设a b 初始都为0,a是shared，b只在cpu0 cache里存在，cpu0执行foo()，cpu1执行bar():</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a = <span class="number">1</span>;</span><br><span class="line">    smp_mb();</span><br><span class="line">    b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>cpu0执行a=1，因为是shared，因此存此操作到store buffer里，并且发了一个invalidate出去，cpu1正在执行b == 0，但是b不在它的cache中，因此发出一个read。</li>
<li>cpu1收到invalidate消息，把它丢到invalidate queue里，然后立马回复了它。cpu0很快收到了回复，开心地把a刷到缓存里，通过了smp_mb()，此时a在它这是modified状态。</li>
<li>cpu0开始接着执行b=1，就它自己有，因此它直接在cache里改了值就行。它又收到read消息，因此刷到内存，返回最新的b=1,同时状态就是shared了。</li>
<li>cpu1收到了read response，b=1进缓存shared。终于跳出了while循环，下一步判断a==1,但此时它cache中还有a=0,之前cpu0给它的invalidate呢，还放在invalidate queue里睡大觉呢，苦逼地出错了。最终才慢悠悠地把cache a给invalidate掉。</li>
</ol>
<p>我们在bar中也加一个memory barrier，保证读cache的时候先确保invalidate queue里清理干净了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a = <span class="number">1</span>;</span><br><span class="line">    smp_mb();</span><br><span class="line">    b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">    smp_mb();</span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其他都一样，当cpu1跳出while循环碰到memory barrier时，它必须要先清理完invalidate queue,把它的cache里的a invalidate掉。现在它的cache没有a了，发出一个read消息被cpu0接收到，cpu0返回了最新的a=1给它，它因此也获得了正确结果。</p>
<p>好了，我们来回顾一下，最终在cpu0和cpu1的流程中都用到了memory barrier来保证正确性。但是cpu0中和invalidate queue没啥关系，cpu1中和store buffer没啥关系。因此，工程师们灵机一动，把它们区分开来，就有了read memory barrier，write memory barrier和all memory barrier。这样就演化出了c中的两个指令smp_wmb()和smp_rmb()。总的看来smp_wmb就是保证当前线程之前store的所有值能被其他线程准确读到，smp_rmb保证了当前线程能读到其他线程改动的各种变量的最新值。</p>

      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/内存/" rel="tag">#内存</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/05/25/transactionTemplate-code-review/" rel="next" title="TransactionTemplate 代码理解">
                <i class="fa fa-chevron-left"></i> TransactionTemplate 代码理解
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/07/15/git-something/" rel="prev" title="GIT的一些小tip">
                GIT的一些小tip <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/06/13/about-memory-barriers/"
           data-title="关于内存屏障的阅读理解" data-url="http://ursa.cc/2016/06/13/about-memory-barriers/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="fourfireliu" />
          <p class="site-author-name" itemprop="name">fourfireliu</p>
          <p class="site-description motion-element" itemprop="description">I am fourfireliu, a Java developer, welcome!</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">3</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cache-Coherence-Protocols"><span class="nav-number">1.</span> <span class="nav-text">Cache Coherence Protocols</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MESI-Protocol-Messages"><span class="nav-number">2.</span> <span class="nav-text">MESI Protocol Messages</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fourfireliu</span>
</div>

<!--<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>-->

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

本站总访问量 <span id="busuanzi_value_site_pv"></span> &nbsp&nbsp&nbsp
您是第<span id="busuanzi_value_site_uv"></span>个来到的小伙伴

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"fourfireliu"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  





  
  
  

  

  

</body>
</html>
